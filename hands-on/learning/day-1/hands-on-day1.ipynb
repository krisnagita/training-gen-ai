{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Training Knowledge Discovery with Generative Chatbot - Day 1\n",
    "This is your day 1 activity, where we will dive into the fundamentals of generative AI. Today, you'll explore the basics, understand key concepts, and get hands-on experience with building and interacting with generative AI systems. Let's get started and unleash your creativity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What will you learn?\n",
    "1. How to create a prompt\n",
    "3. How to ask question and get your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up library and API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please install this library to run the function in the activity Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain faiss-cpu openai pypdf\n",
    "# !pip install langchain-community\n",
    "# !pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.callbacks import OpenAICallbackHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this step you will compose the prompt. you can experiment with your prompt. Use your creativity!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "    You are a doctor. people come to you to consult abour their health ..... \n",
    "    Use the following context to answer the question:\\n\\n\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set Your LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this step you will combine the prompt and LLM using langchain. This step is the final step before you can run your first gen AI Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT 4o\n",
    "def ChatGPT():\n",
    "    model = AzureChatOpenAI(\n",
    "        temperature = 0.0,\n",
    "        azure_deployment= os.getenv(\"AZURE_DEPLOYMENT_GPT4\"),\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT_GPT4\"),\n",
    "        openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY_GPT4\"),\n",
    "        openai_api_version = os.getenv(\"OPENAI_API_VERSION_GPT4\"),\n",
    "        callbacks = [OpenAICallbackHandler()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=ChatGPT(), \n",
    "                    prompt=prompt_template, \n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Let's Ask Some Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"what happen when i cough a lot?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_chain.invoke({\n",
    "    \"question\": question,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the answer\n",
    "print(\"Question:\", response['question'])\n",
    "print(\"Answer:\", response['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
